{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2df2cae3-52af-4abf-8f19-060e0f9bc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfosd(mn1,mn2,sd1,sd2):\n",
    "\n",
    "    m = mn2-mn1\n",
    "    s = 3*(sd2-sd1)\n",
    "    \n",
    "    dX = [m-s,m]\n",
    "    \n",
    "    if all(x > 0 for x in dX):\n",
    "        flag = -1\n",
    "    elif all(x < 0 for x in dX):\n",
    "        flag = 1\n",
    "    else: \n",
    "        flag = 0\n",
    "        \n",
    "    return flag, dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97cbfddd-4df7-41bb-84d9-9e985ab2e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "\n",
    "def sosd(name,loc_sc_1,loc_sc_2,n):\n",
    "# def sosd(name,loc_sc_1,loc_sc_2,mn1,mn2,sd1,sd2,n):\n",
    "    \n",
    "    # xmin = min(mn1 - 5*sd1, mn2 - 5*sd2);\n",
    "    # xmax = max(mn1 + 5*sd1, mn2 + 5*sd2);\n",
    "    # x = np.linspace(xmin,xmax,n);\n",
    "    \n",
    "    int_F1 = np.zeros((n,1));\n",
    "    int_F2 = np.zeros((n,1));\n",
    "    \n",
    "    loc1, scale1 = loc_sc_1\n",
    "    loc2, scale2 = loc_sc_2\n",
    "    \n",
    "    cdf1 = getattr(sts, name)(loc=loc1, scale=scale1) #Generate appropriate CDFs\n",
    "    cdf2 = getattr(sts, name)(loc=loc2, scale=scale2)\n",
    "\n",
    "    x1 = cdf1.ppf([0.0001, 0.9999])\n",
    "    x2 = cdf2.ppf([0.0001, 0.9999])\n",
    "    xmin = min(x1[0], x2[0]);\n",
    "    xmax = max(x1[1], x2[1]);\n",
    "    x = np.linspace(xmin,xmax,n);\n",
    "    \n",
    "    for i in range(n-1): #1:n-1\n",
    "\n",
    "        int_F1[i+1] = np.trapz(cdf1.cdf(x[:i+1]), x[:i+1])\n",
    "        int_F2[i+1] = np.trapz(cdf2.cdf(x[:i+1]), x[:i+1])\n",
    "    \n",
    "    d_F = int_F1 - int_F2;\n",
    "    s_d_F = np.sum(d_F);\n",
    "    \n",
    "    if s_d_F > 0: flag = -1; #Second one dominant\n",
    "    elif s_d_F < 0: flag = 1; #First one dominant\n",
    "    else: flag = 0; #Indistinguishable => identical\n",
    "\n",
    "    return flag, d_F, int_F1, int_F2, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "eee9b8b7-cccf-4d46-b0bf-a0c1d84783ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psort(name, pars, x, n):\n",
    "\n",
    "    pars = np.asarray(pars, dtype=float)\n",
    "    x    = np.asarray(x)\n",
    "\n",
    "    loc  = pars[:, 0]\n",
    "    scale = pars[:, 1]\n",
    "    dist = getattr(sts, name)\n",
    "\n",
    "    mn = dist.mean(loc=loc, scale=scale)\n",
    "    vr = dist.var(loc=loc, scale=scale)\n",
    "\n",
    "    sd = np.sqrt(vr)\n",
    "    dist_mat = np.column_stack([mn, sd, pars])\n",
    "    \n",
    "    u, unique_idx, rInd = np.unique(\n",
    "        dist_mat, axis=0, return_index=True, return_inverse=True)\n",
    "    idx_order = np.argsort(unique_idx)\n",
    "    distU = dist_mat[unique_idx[idx_order]]\n",
    "    rInd = idx_order[rInd]\n",
    "\n",
    "    mnU  = distU[:, 0]\n",
    "    sdU  = distU[:, 1]\n",
    "    parsU = distU[:, 2:]\n",
    "    lenU = distU.shape[0]\n",
    "    flag = np.zeros((lenU, lenU))\n",
    "\n",
    "    for i in range(lenU):\n",
    "        for j in range(i+1, lenU):\n",
    "\n",
    "            flag_ji, _ = mfosd(mnU[j], mnU[i], sdU[j], sdU[i])\n",
    "            flag[j, i] = flag_ji\n",
    "            \n",
    "            if flag[j, i] == 0:\n",
    "                flag_ji, *_ = sosd(name, parsU[j], parsU[i], n)\n",
    "                flag[j, i] = flag_ji\n",
    "                \n",
    "    lower = np.tril(flag)\n",
    "    flag_skew = lower - lower.T\n",
    "    fRank_unique = np.sum(flag_skew, axis=1)\n",
    "    fRank = fRank_unique[rInd]\n",
    "    sortOrd = np.argsort(-fRank)\n",
    "\n",
    "    xS   = x[sortOrd]\n",
    "    parS = pars[sortOrd]\n",
    "    mnS  = mn[sortOrd]\n",
    "    vrS  = vr[sortOrd]\n",
    "\n",
    "    return xS, parS, mnS, vrS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "33af02b4-c6cd-4fe7-a12f-07fb4d027811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillOut(out,L,x=None,pars=None,y=None,u=None,ind_F=None,ind_Fi=None,l=None,\n",
    "            p_excd_F=None,p_excd_Fi=None,n_gen=None,n_C=None,n_F=None,mn=None,\n",
    "            vr=None,C=None,mn_F=None,vr_F=None,C_F=None):\n",
    "    \n",
    "    out[L]['x'] = x; \n",
    "    out[L]['pars'] = pars; \n",
    "    out[L]['y'] = y; \n",
    "    out[L]['u'] = u; \n",
    "       \n",
    "    out[L]['ind_F'] = ind_F; \n",
    "    out[L]['ind_Fi'] = ind_Fi\n",
    "       \n",
    "    out[L]['t_i'] = l\n",
    "    out[L]['p_star'] = p_excd_F\n",
    "    out[L]['p_ij'] = p_excd_Fi\n",
    "       \n",
    "    out[L]['N_i'] = n_gen\n",
    "    out[L]['N_C'] = n_C\n",
    "    out[L]['N_F'] = n_F\n",
    "       \n",
    "    out[L]['p_Ci']['mn'] = mn\n",
    "    out[L]['p_Ci']['vr'] = vr\n",
    "    out[L]['p_Ci']['C'] = C\n",
    "       \n",
    "    out[L]['p_Fi']['mn'] = mn_F\n",
    "    out[L]['p_Fi']['vr'] = vr_F\n",
    "    out[L]['p_Fi']['C'] = C_F\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6b8e7e12-d8cb-487b-abf1-7a654e09c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_out_funcs(out_dist): #These are loc-scale family only for now: legacy from initial version\n",
    "    out_dists = ['norm', 'uniform', 'logistic', 'laplace', 't'];\n",
    "    \n",
    "    if out_dist.lower() not in out_dists:\n",
    "        raise(Exception('Unrecognized output distribution.'))\n",
    "        \n",
    "    dist_obj = getattr(sts, out_dist)  \n",
    "    \n",
    "    get_mean_var = lambda loc, sc: (dist_obj(loc, sc).mean(), dist_obj(loc, sc).var())\n",
    "    excd_fun = lambda loc, sc, lev: dist_obj(loc, sc).sf(lev)\n",
    "\n",
    "    return get_mean_var, excd_fun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "601ad6b4-22c7-434e-8774-956fa8474a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmma(propFunc, excdFunc, dist, func, d, seeds, par1, par2, level, nL, nC):\n",
    "\n",
    "    nS = int(np.ceil((nL - nC) / nC))  \n",
    "\n",
    "    s = np.std(seeds[:, :, 0], axis=0)        \n",
    "    s = np.tile(s, (nC, 1))                     \n",
    "\n",
    "    prop = lambda x: propFunc(x, s)\n",
    "\n",
    "    pA = np.zeros((nS, d))\n",
    "\n",
    "    for k in range(nS):\n",
    "        \n",
    "        urand = np.random.rand(nC, d)\n",
    "\n",
    "        pstar = prop(seeds[:, :, k])\n",
    "\n",
    "        r = dist.pdf(pstar) / dist.pdf(seeds[:, :, k])   \n",
    "        accept = urand < r[:, None]                       \n",
    "\n",
    "        pA[k, :] = np.mean(accept, axis=0)\n",
    "\n",
    "        zeta = seeds[:, :, k].copy()\n",
    "        zeta[accept] = pstar[accept]\n",
    "\n",
    "        par1[:, k+1] = par1[:, k]\n",
    "        par2[:, k+1] = par2[:, k]\n",
    "\n",
    "        rows = np.any(accept, axis=1)\n",
    "\n",
    "        if np.any(rows):\n",
    "            p1_new, p2_new = func(zeta[rows, :])    \n",
    "            par1[rows, k+1] = p1_new\n",
    "            par2[rows, k+1] = p2_new\n",
    "\n",
    "        seeds[:, :, k+1] = seeds[:, :, k]\n",
    "\n",
    "        pInFi = excdFunc(np.column_stack([par1[:, k+1], par2[:, k+1]]), level)\n",
    "\n",
    "        urandF = np.random.rand(nC)\n",
    "        inFi = urandF < pInFi\n",
    "\n",
    "        seeds[inFi, :, k+1] = zeta[inFi, :]\n",
    "        par1[~inFi, k+1] = par1[~inFi, k]\n",
    "        par2[~inFi, k+1] = par2[~inFi, k]\n",
    "\n",
    "    return seeds, par1, par2, pA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "82420b0e-b7fe-40eb-b5cb-d599ad1e59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def varindepprod(mu,var):\n",
    "    '''\n",
    "    %%% Variance of the product of two independent distributions.\n",
    "    %%% Inputs:\n",
    "    %%% \tmu -  a vector of expectations\n",
    "    %%% \tvar - a vector of variances\n",
    "    '''\n",
    "    \n",
    "    n = len(mu); #Number of RV\n",
    "    \n",
    "    if n == 1: varprod = var;\n",
    "    elif n == 2:\n",
    "        varprod = np.prod(var) + var[0]*mu[1]**2 + var[1]*mu[0]**2;\n",
    "    else:\n",
    "        v = varindepprod(mu[1:n-1], var[1:n-1]);\n",
    "        varprod = var[-1]*v + v*mu[-1]**2 + var[-1]*np.prod(mu[:-1]**2);\n",
    "    \n",
    "    return varprod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "dcf977b5-24ae-401d-a506-710cc7708edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight(msg,textcolor=(246,247,246),background=(25,35,45),): # rgb codes (default for Spyder console)\n",
    "    s = '\\33[38;2;'\n",
    "    for _ in textcolor : s += str(_) + ';'\n",
    "    s += '48;2'\n",
    "    for _ in background : s += ';' + str(_) \n",
    "    print(('{0}' + msg).format(s+'m'),'\\33[0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "8e576cba-47d8-4f5e-8077-b77a1c0ca93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psus(func, d, t_star, n, p,\n",
    "         out_dist,\n",
    "         inp_dist = {'name':'uniform', 'parameters':[0,1]}):\n",
    "    '''\n",
    "    %%% Inputs:\n",
    "    %%%     func    - single input function handle to the probabilistic code\n",
    "    %%%     d       - dimensionality of the input space (scalar)\n",
    "    %%%     t_star  - critical threshold (scalar)\n",
    "    %%%     n       - target number of samples per P-SuS level (scalar)\n",
    "    %%%     p       - target level probability (scalar)\n",
    "    %%%     out_dist - name of the output distribution (char)\n",
    "    %%%     inp_dist - name and parameter tuple for the input distribution \n",
    "    %%%               (1-by-2 cell). If left unspecified, a uniform distro on\n",
    "    %%%               [0,1] is used.\n",
    "    %%%\n",
    "    %%% Outputs:\n",
    "    %%% \tpF\t  - probability of failure structure, with deterministic pF and\n",
    "    %%% \t\t\tinformation about the pF distribution - \n",
    "    %%%\t\t\t\tmean and variance under independence and perfect dependence\n",
    "    %%%\t\t\t\tbetween levels.\n",
    "    %%% \tsOutF - structure containing full information about the psus run\n",
    "    %%%\n",
    "    %%% Only a normal proposal distribution is used for now.\n",
    "    %%% The function requires Statistics and Machine Learning Toolbox in MATLAB\n",
    "    %%% to be installed.'''\n",
    "    \n",
    "    # %% PREPARE PRELIMINARIES\n",
    "    get_mean_var, excd_fun = generate_out_funcs(out_dist); #Check that output distribution is\n",
    "                                        #available and get moment transform\n",
    "                                        #and membership functions\n",
    "    zero_prob = False;\n",
    "    logc_acc = lambda pTarg: np.random.rand(len(pTarg), 1) < pTarg #Acceptance function\n",
    "    \n",
    "    d_func = lambda x, s: np.random.normal(x,s) #Construct proposal distribution\n",
    "    \n",
    "    p0N = p*n #Target number of seeds\n",
    "    \n",
    "    # %% PREPARE INPUTS\n",
    "    dist_obj = getattr(sts, inp_dist['name'])(*inp_dist['parameters'])\n",
    "    \n",
    "    # %% Sample the input\n",
    "    x = dist_obj.rvs((n,d));\n",
    "    \n",
    "    # %% OBTAIN RESPONSE - Assume 2 parameter location scale for now\n",
    "    p1, p2 = func(x); #Get output distribution parameters\n",
    "    y, u = get_mean_var(p1, p2);\n",
    "    # y = D(:,1);\n",
    "    # u = D(:,2);\n",
    "    \n",
    "    # %% RANK RESPONSES\n",
    "    [x_sort, par_sort, y_sort, uncert_sort] = psort(out_dist,[p1,p2],x,50);\n",
    "    \n",
    "    # %% Output\n",
    "    inp_par = {'func':func,'outdist':out_dist,'dim':d,'t_star':t_star,\n",
    "                  'p_0':p,'N':n}\n",
    "    dict_out = {'x':[],'y':[],'u':[],'pars':[],'ind_F':[],'ind_Fi':[],'t_i':[],\n",
    "    \t'p_star':[],'p_ij':[],'N_i':[],'N_C':[],'p_Ci':[],'N_F':[],'p_Fi':[]};\n",
    "    \n",
    "    \n",
    "    # %% Set loop\n",
    "    L = 0; #Conditional Level\n",
    "    n_gen = [n]; #Samples at uncond level\n",
    "    n_pt = [n]; #To correctly compute pF if no conditional levels are needed\n",
    "    \n",
    "    mn = []\n",
    "    vr = []\n",
    "    C_F = []\n",
    "    C = []\n",
    "    # %% Run loop\n",
    "    while True: #n_F < n*p\n",
    "        # %% Record failure\n",
    "        p_excd_F = excd_fun(par_sort,t_star); #Probability of exceeding threshold\n",
    "        ind_F = logc_acc(p_excd_F);\n",
    "        n_F = np.sum(ind_F);\n",
    "        \n",
    "        # %% Compute moments of counting distro\n",
    "        mn.append(np.sum(p_excd_F)) #Mean - can be used in both Poisson and Gaussian approx.\n",
    "        vr.append(np.sum( p_excd_F*(1-p_excd_F) )) #Variance - for Gaussian approx.;\n",
    "        \n",
    "        # %% Compute scaling constant - N_F\n",
    "        C_F.append(min( mn[L]/3/np.sqrt(vr[L]), (n_gen[L]-mn[L])/3/np.sqrt(vr[L]) ));\n",
    "        \n",
    "        # %% Fill in new data\n",
    "        # sOut = fillOut(sOut, L, x_sort, par_sort, y_sort, uncert_sort, ind_F,\n",
    "        #                None, None, p_excd_F, None, n_gen[L], None, n_F, None,\n",
    "        #                None, None, mn[L], vr[L], CF[L]);\n",
    "        dict_out = fillOut(dict_out, L, x_sort, par_sort, y_sort, uncert_sort, ind_F,\n",
    "                       p_excd_F=p_excd_F, n_gen=n_gen[L], n_F=n_F, mn_F=mn[L],\n",
    "                       vr_F=vr[L], C_F=C_F[L]);\n",
    "                                           \n",
    "        if n_F > n*p: break\n",
    "    \t\n",
    "    \t# %% CALCULATE LEVEL\n",
    "        level = y_sort[p0N];\n",
    "        \n",
    "        # %% Next level probabilities\n",
    "        p_in_Fi = excd_fun(par_sort, level); #Probability of exceedance\n",
    "        \t\n",
    "        # %% Counting distribution moments\n",
    "        mn.append(np.sum(p_in_Fi)) #Mean - can be used in both Poisson and Gaussian approx.\n",
    "        vr.append(np.sum( p_in_Fi*(1-p_in_Fi) )) #Variance - for Gaussian approx.;\n",
    "        \n",
    "        # %% Compute scaling constant - N_C\n",
    "        C.append(min( mn[L]/3/np.sqrt(vr[L]), (n_gen[L]-mn[L])/3/np.sqrt(vr[L]) ))\n",
    "        \n",
    "        # %% Choose seeds\n",
    "        ind_Fi = logc_acc(p_in_Fi);\n",
    "        # ind_Fi = find(ind_Fi,floor(mn(L)),'first');\n",
    "        ind_Fi = np.where(ind_Fi != 0)[np.floor(mn[L])] #Verify that this is equivalent to the above\n",
    "        \n",
    "        n_pt.append(len(ind_Fi)) \n",
    "        \n",
    "        seeds = x_sort[ind_Fi,:];\n",
    "        \t\n",
    "        # %% Fill in update\n",
    "        dict_out = fillOut(dict_out,L,ind_Fi=ind_Fi,l=level,p_excd_Fi=p_in_Fi,\n",
    "                           n_C=n_pt[L],mn=mn[L],vr=vr[L],C=C[L]);\n",
    "        \n",
    "        # %% Use MMA to populate the conditional level\n",
    "        condSamp, p1, p2 = pmma(d_func, excd_fun, dist_obj, func, d, seeds,\n",
    "                                par_sort[ind_Fi,1], par_sort[ind_Fi,2], level,\n",
    "                                n, n_pt[L]);\n",
    "        \n",
    "        # p1 = p1(:);\n",
    "        # p2 = p2(:);\n",
    "        p1 = p1.flatten();\n",
    "        p2 = p2.flatten();\n",
    "        \n",
    "        L += 1;\n",
    "        \n",
    "        # %% Restructuring 'seeds' for sorting\n",
    "        # rows, _ = condSamp.shape #Find number of rows for reshaping\n",
    "        # condSamp = reshape(permute(condSamp,[1,3,2]),rows,d); #Reshape samples appropriately\n",
    "        # condSamp = reshape(permute(condSamp,[1,3,2]),rows,d); #Reshape samples appropriately\n",
    "\n",
    "        rows = condSamp.shape[0]\n",
    "        condSamp_perm = np.transpose(condSamp, (0, 2, 1))\n",
    "        condSamp = condSamp_perm.reshape(rows, d)\n",
    "\n",
    "        n_gen.append(len(condSamp));\n",
    "        \n",
    "        y, u = get_mean_var(p1, p2);\n",
    "        \n",
    "        [x_sort,par_sort,y_sort,uncert_sort] = psort(out_dist,[p1,p2],condSamp,50);\n",
    "        \n",
    "        # %% Timing\n",
    "        if L == 17:\n",
    "            highlight('Probability of failure is zero to machine precision\\nExiting...', (255,100,0))\n",
    "            zero_prob = True\n",
    "            break\n",
    "    \n",
    "    # %% Calculate probability of failure\n",
    "    L -= 1; #Adjust to correct number of levels\n",
    "    \n",
    "    p_F = {}\n",
    "    if ~zero_prob:\n",
    "        # % Independence among Bernoulli's\n",
    "        p_F['p_F'] = np.prod( n_pt[1:L]/n_gen[1:L] ) * n_F/n_gen[L+1]\n",
    "        p_F['mean'] = np.prod(mn/n_gen);\n",
    "        p_F['var'] = varindepprod(mn,vr)/np.prod(n_gen**2);\n",
    "        \n",
    "        # % Maximal allowable dependence\n",
    "        # C = [dict_out(:).p_Ci];\n",
    "        # C = [[C(:).C].T; sOut(end).p_Fi.C];\n",
    "        p_F.Cvar = varindepprod(mn, C**2*vr)/np.prod(n_gen**2);\n",
    "        \n",
    "    else:\n",
    "        p_F['p_F'] = 0;\n",
    "        p_F['mean'] = 0;\n",
    "        p_F['var'] = np.inf;\n",
    "    \n",
    "    dict_out_F = {'Results': dict_out, 'p_F': p_F, 'Inputs': inp_par}\n",
    "    \n",
    "    return p_F, dict_out_F"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
